{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loadin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(data)\n",
    "Dataset = data.DataBinary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from: ./Data/4-15-divided-tokenized-vectored/test/\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset('./Data/4-15-divided-tokenized-vectored/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 14, 1024)\n",
      "(3, 21, 1024)\n",
      "(3, 33, 1024)\n",
      "(3, 12, 1024)\n",
      "(3, 49, 1024)\n",
      "(3, 9, 1024)\n",
      "(3, 50, 1024)\n",
      "(3, 29, 1024)\n",
      "(3, 18, 1024)\n",
      "(3, 36, 1024)\n",
      "(3, 23, 1024)\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for x,y in ds.get_batch(batch_size=3):\n",
    "#     print(y)\n",
    "    print(x[0].shape)\n",
    "    step += 1\n",
    "    if step > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69965\n"
     ]
    }
   ],
   "source": [
    "print(len(ds.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): GRU(1024, 1024, num_layers=2, batch_first=True)\n",
       "  (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(model)\n",
    "RNN = model.RNN\n",
    "rnn = RNN(1024,3,nb_layers=2,nb_units=1024)\n",
    "rnn.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auxiliary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(s, maxlen):\n",
    "    padded = np.zeros((maxlen,s.shape[1]), dtype=np.double)\n",
    "    if len(s) > maxlen: padded[:] = s[:maxlen]\n",
    "    else: padded[:len(s)] = s\n",
    "    return padded\n",
    "\n",
    "def prepare_batch(x,y):\n",
    "    x.sort(key=lambda item: -item.shape[1])\n",
    "    x_len = []\n",
    "    for i in range(len(x)):\n",
    "        l = min(x[i].shape[1],50)\n",
    "        x[i] = pad_data(x[i][0],50)\n",
    "        x_len.append(l)\n",
    "    x = np.array(x)\n",
    "    x_len = np.array(x_len)\n",
    "    x = torch.from_numpy(x).float().cuda()\n",
    "    x_len = torch.from_numpy(x_len).float()\n",
    "    y = torch.from_numpy(np.array(y,dtype=int)).cuda()\n",
    "    return x, x_len, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, batch_gen, batch_size, ds, epoch = 1):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    total_epoch_loss = 0\n",
    "    total_epoch_acc = 0\n",
    "    model.cuda()\n",
    "#     optim = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),lr = 0.001)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "#     optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    steps = 0\n",
    "    model.train()\n",
    "    for x, y in batch_gen(ds, batch_size=batch_size):\n",
    "        x,x_len,y = prepare_batch(x,y)\n",
    "        y = torch.autograd.Variable(y).long()\n",
    "#         optim.zero_grad()\n",
    "        model.zero_grad()\n",
    "        y_hat = model(x,x_len)\n",
    "        loss = loss_fn(y_hat,y)\n",
    "        num_currect = (torch.max(y_hat, 1)[1].view(y.size()).data == y.data).float().sum()\n",
    "        acc = 100.0 * num_currect/batch_size\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        steps += 1\n",
    "        total_epoch_loss += loss.item()\n",
    "        total_epoch_acc += acc.item()\n",
    "        \n",
    "        if steps % 100 == 0:\n",
    "            print (f'Epoch: {epoch+1}, batch: {steps}, Training Loss: {total_epoch_loss/steps:.4f}, Training Accuracy: {total_epoch_acc/steps: .2f}%')\n",
    "            \n",
    "        \n",
    "    return total_epoch_loss/steps, total_epoch_acc/steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(ds, batch_size=32, shuffeling=True):\n",
    "    indices = np.arange(len(ds.data))\n",
    "    d = []\n",
    "    s = 0\n",
    "    for i in indices:\n",
    "        if ds.labels[i] == '1':\n",
    "            s +=1\n",
    "            if np.random.rand() > 0.2:\n",
    "                d.append(i)\n",
    "    indices = np.delete(indices,d)\n",
    "#     print(len(ds.data),len(indices),len(d),s)\n",
    "    if shuffeling:\n",
    "        np.random.shuffle(indices)\n",
    "    for i in range(0,len(indices),batch_size):\n",
    "        d = indices[i:i+batch_size]\n",
    "        x = [ds.data[i] for i in d]\n",
    "        y = [ds.labels[i] for i in d]\n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, batch: 100, Training Loss: 2.9719, Training Accuracy:  33.50%\n",
      "Epoch: 1, batch: 200, Training Loss: 4.6278, Training Accuracy:  33.02%\n",
      "Epoch: 1, batch: 300, Training Loss: 3.4595, Training Accuracy:  33.36%\n",
      "Epoch: 1, batch: 400, Training Loss: 2.8708, Training Accuracy:  33.37%\n",
      "(2.600925504403599, 33.23622881355932)\n",
      "Epoch: 2, batch: 100, Training Loss: 1.1436, Training Accuracy:  33.45%\n",
      "Epoch: 2, batch: 200, Training Loss: 1.1356, Training Accuracy:  33.57%\n",
      "Epoch: 2, batch: 300, Training Loss: 1.1246, Training Accuracy:  33.97%\n",
      "Epoch: 2, batch: 400, Training Loss: 1.1190, Training Accuracy:  33.73%\n",
      "(1.1165214696001349, 33.718152866242036)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-296-c309fded0d30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-294-1c9976da4ee0>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, batch_gen, batch_size, ds, epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtotal_epoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtotal_epoch_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(train_epoch(rnn,get_batch,64,ds,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for x, y in ds.get_batch(batch_size=10):\n",
    "#         print(len(x))\n",
    "    x,x_len,y = prepare_batch(x,y)\n",
    "#         print(steps,x.shape)\n",
    "#     optim.zero_grad()\n",
    "    y_hat = rnn(x,x_len)\n",
    "    i += 1\n",
    "    if i > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017],\n",
      "        [ 0.0433,  0.1417, -0.0017]], device='cuda:0')\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "tensor([2, 1, 2, 1, 1, 1, 1, 0, 2, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_hat.data)\n",
    "print(y_hat.cpu().data.numpy().argmax(axis=1))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 10000, 1: 49965, 2: 10000}\n"
     ]
    }
   ],
   "source": [
    "s = {0:0,1:0,2:0}\n",
    "for i in ds.labels:\n",
    "    s[int(i)] += 1\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9514, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(F.cross_entropy(y_hat, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8375, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4739, -0.8596, -0.8077, -0.3942,  0.4430],\n",
      "        [ 1.1719,  0.5002, -0.5580, -0.3177,  0.5473],\n",
      "        [-0.2881, -1.8407,  0.9588, -0.6890, -1.6679]], requires_grad=True)\n",
      "tensor([1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(input)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8]\n",
      "[1 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6,7,8])\n",
    "print(a)\n",
    "a = np.delete(a,[1,2])\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
